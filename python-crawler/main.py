"""
æ™ºèƒ½æŠ€æœ¯èµ„è®¯èšåˆç³»ç»Ÿ - Python çˆ¬è™«å…¥å£
"""
import sys
import argparse
from datetime import datetime

from crawlers.github_crawler import crawl_github_trending
from crawlers.juejin_crawler import crawl_juejin_hot
from crawlers.hackernews_crawler import crawl_hackernews
from crawlers.producthunt_crawler import crawl_ai_tools
from crawlers.ai_papers_crawler import crawl_huggingface_papers, crawl_arxiv_ai
from crawlers.football_crawler import get_football_summary, format_football_markdown
from redis_client import redis_client
from config import FOOTBALL_API_KEY

# é…ç½®
DAYS_LIMIT = 10


def run_crawlers():
    """
    è¿è¡Œæ‰€æœ‰çˆ¬è™«å¹¶å­˜å‚¨ç»“æœ
    ä¼˜å…ˆçº§ï¼šAIå†…å®¹ > å…¶ä»–æŠ€æœ¯å†…å®¹
    """
    print(f"\n{'='*50}")
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹çˆ¬å–æŠ€æœ¯èµ„è®¯...")
    print(f"{'='*50}\n")
    
    all_articles = []
    
    # === ä¼˜å…ˆçº§1: AIå†…å®¹ ===
    print("=" * 30)
    print("ğŸ“Œ ä¼˜å…ˆçˆ¬å– AI å†…å®¹")
    print("=" * 30)
    
    # 1. AIåº”ç”¨ - å¤šæºèšåˆ (Futurepedia/Toolify/GitHub AI)
    print("[1/6] æ­£åœ¨çˆ¬å– AI åº”ç”¨å·¥å…·...")
    try:
        ai_tools = crawl_ai_tools(count=5, days_limit=DAYS_LIMIT)
        all_articles.extend(ai_tools)
    except Exception as e:
        print(f"  âš  AIå·¥å…·çˆ¬å–å¤±è´¥: {e}")
    
    # 2. AIå‰æ²¿ - Hugging Face Papers
    print("[2/6] æ­£åœ¨çˆ¬å– Hugging Face AI è®ºæ–‡...")
    try:
        hf_articles = crawl_huggingface_papers(count=5, days_limit=DAYS_LIMIT)
        all_articles.extend(hf_articles)
    except Exception as e:
        print(f"  âš  Hugging Face çˆ¬å–å¤±è´¥: {e}")
    
    # 3. AIå‰æ²¿ - arXiv (å¤‡ç”¨)
    print("[3/6] æ­£åœ¨çˆ¬å– arXiv AI è®ºæ–‡...")
    try:
        arxiv_articles = crawl_arxiv_ai(count=3, days_limit=DAYS_LIMIT)
        all_articles.extend(arxiv_articles)
    except Exception as e:
        print(f"  âš  arXiv çˆ¬å–å¤±è´¥: {e}")
    
    # === ä¼˜å…ˆçº§2: è¡¥å……æ¥æºï¼ˆå‡å°‘æ•°é‡ï¼‰ ===
    print("\n" + "=" * 30)
    print("ğŸ“ çˆ¬å–è¡¥å……æ¥æº")
    print("=" * 30)
    
    # 4. GitHub Trending (åªå–4ç¯‡ï¼Œä¸»è¦çœ‹AIç›¸å…³)
    print("[4/6] æ­£åœ¨çˆ¬å– GitHub Trending...")
    try:
        github_articles = crawl_github_trending()[:4]
        all_articles.extend(github_articles)
    except Exception as e:
        print(f"  âš  GitHub çˆ¬å–å¤±è´¥: {e}")
    
    # 5. æ˜é‡‘çƒ­æ¦œ (åªå–3ç¯‡)
    print("[5/6] æ­£åœ¨çˆ¬å–æ˜é‡‘çƒ­æ¦œ...")
    try:
        juejin_articles = crawl_juejin_hot()[:3]
        all_articles.extend(juejin_articles)
    except Exception as e:
        print(f"  âš  æ˜é‡‘çˆ¬å–å¤±è´¥: {e}")
    
    # 6. Hacker News (åªå–3ç¯‡)
    print("[6/6] æ­£åœ¨çˆ¬å– Hacker News...")
    try:
        hn_articles = crawl_hackernews(3)
        all_articles.extend(hn_articles)
    except Exception as e:
        print(f"  âš  Hacker News çˆ¬å–å¤±è´¥: {e}")
    
    # å­˜å…¥ Redis
    print(f"\n[å­˜å‚¨] å…± {len(all_articles)} ç¯‡æ–‡ç« ï¼Œæ­£åœ¨å­˜å…¥ Redis...")
    saved_count = redis_client.save_articles(all_articles)
    print(f"[å­˜å‚¨] æˆåŠŸå­˜å…¥ {saved_count} ç¯‡æ–‡ç« ")
    
    # === è¶³çƒæ•°æ® ===
    print("\n" + "=" * 30)
    print("âš½ è·å–è¶³çƒæ•°æ®")
    print("=" * 30)
    
    try:
        football_data = get_football_summary(FOOTBALL_API_KEY)
        if football_data.get("standings") or football_data.get("matches"):
            redis_client.save_football(football_data)
            print("[Football] è¶³çƒæ•°æ®å·²å­˜å…¥ Redis")
        else:
            print("[Football] æœªè·å–åˆ°è¶³çƒæ•°æ®")
    except Exception as e:
        print(f"[Football] è·å–å¤±è´¥: {e}")
    
    # æ‰“å°æ±‡æ€»
    print(f"\n{'='*50}")
    print("çˆ¬å–å®Œæˆï¼æ±‡æ€»ï¼š")
    print(f"  ğŸš€ AIåº”ç”¨ (å¤šæºèšåˆ): {len(ai_tools) if 'ai_tools' in dir() else 0} ç¯‡")
    print(f"  ğŸ”¬ AIå‰æ²¿ (HuggingFace): {len(hf_articles) if 'hf_articles' in dir() else 0} ç¯‡")
    print(f"  ğŸ“„ AIå‰æ²¿ (arXiv): {len(arxiv_articles) if 'arxiv_articles' in dir() else 0} ç¯‡")
    print(f"  ğŸ“¦ GitHub Trending: {len(github_articles) if 'github_articles' in dir() else 0} ç¯‡")
    print(f"  ğŸ“ æ˜é‡‘çƒ­æ¦œ: {len(juejin_articles) if 'juejin_articles' in dir() else 0} ç¯‡")
    print(f"  ğŸ”¶ Hacker News: {len(hn_articles) if 'hn_articles' in dir() else 0} ç¯‡")
    print(f"  âš½ è¶³çƒæ•°æ®: {'å·²è·å–' if 'football_data' in dir() and football_data else 'æœªè·å–'}")
    print(f"  ğŸ“Š æ€»è®¡: {len(all_articles)} ç¯‡")
    print(f"  ğŸ”‘ Redis Key: {redis_client.get_today_key()}")
    print(f"{'='*50}\n")
    
    return all_articles


def test_redis():
    """æµ‹è¯• Redis è¿æ¥"""
    print("æ­£åœ¨æµ‹è¯• Redis è¿æ¥...")
    if redis_client.ping():
        print("âœ“ Redis è¿æ¥æˆåŠŸ!")
        articles = redis_client.get_articles()
        print(f"âœ“ å½“å‰å­˜å‚¨ {len(articles)} ç¯‡æ–‡ç« ")
    else:
        print("âœ— Redis è¿æ¥å¤±è´¥!")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="æŠ€æœ¯èµ„è®¯çˆ¬è™«")
    parser.add_argument("--test", action="store_true", help="ä»…æµ‹è¯• Redis è¿æ¥")
    parser.add_argument("--show", action="store_true", help="æ˜¾ç¤ºå½“å‰å­˜å‚¨çš„æ–‡ç« ")
    args = parser.parse_args()
    
    if args.test:
        test_redis()
    elif args.show:
        articles = redis_client.get_articles()
        if articles:
            print(f"å½“å‰å­˜å‚¨ {len(articles)} ç¯‡æ–‡ç« ï¼š\n")
            for i, a in enumerate(articles, 1):
                print(f"{i}. [{a['source']}] {a['title']}")
                print(f"   URL: {a['url']}")
                print(f"   æè¿°: {a['description'][:80]}...")
                print()
        else:
            print("æš‚æ— å­˜å‚¨çš„æ–‡ç« ")
    else:
        run_crawlers()


if __name__ == "__main__":
    main()
